# Email-Classification-SVM

ğŸ“§ Destek VektÃ¶r Makineleri (SVM) ile E-posta SÄ±nÄ±flandÄ±rmasÄ±Bu proje, bir e-postanÄ±n KiÅŸisel (0) mÄ± yoksa Ä°ÅŸ (1) e-postasÄ± mÄ± olduÄŸunu, gÃ¶nderici formalitesi ve iliÅŸki puanlarÄ±na dayalÄ± olarak tahmin etmek iÃ§in bir Destek VektÃ¶r Makineleri (Support Vector Machines - SVM) modeli uygulamaktadÄ±r.ğŸš€ Proje Ã–zellikleriModel: Destek VektÃ¶r Makineleri (SVM)Ã‡ekirdekler: Lineer (Linear) ve RBF (Radial Basis Function)Veri Seti: email_classification_svm.csvKÃ¼tÃ¼phaneler: pandas, numpy, seaborn, matplotlib, scikit-learnğŸ“Š Veri Seti ve Ã–zelliklerVeri seti, her biri 1000 gÃ¶zlem iÃ§eren iki ana Ã¶zellik (Feature) ve bir hedef deÄŸiÅŸkenden (Target) oluÅŸmaktadÄ±r:Ã–zellik AdÄ±AÃ§Ä±klamasubject_formality_scoreE-posta konusunun formalite puanÄ±.sender_relationship_scoreGÃ¶nderici ile olan iliÅŸkinin yakÄ±nlÄ±k puanÄ±.email_type (Hedef)E-posta tÃ¼rÃ¼: 0 = KiÅŸisel, 1 = Ä°ÅŸ E-postasÄ±.Bu Ã¶zellikler, makine Ã¶ÄŸrenimi modelinin performansÄ±nÄ± optimize etmek iÃ§in muhtemelen Ã¶nceden normalize edilmiÅŸtir.Veri GÃ¶rselleÅŸtirme (Separability)Not defterindeki gÃ¶rselleÅŸtirme adÄ±mlarÄ± (pairplot ve scatter plot), veri noktalarÄ±nÄ±n iki sÄ±nÄ±fa (0 ve 1) gÃ¶re Ã§ok net bir ÅŸekilde ayrÄ±labilir olduÄŸunu gÃ¶stermektedir. Bu yÃ¼ksek ayrÄ±labilirlik, SVM gibi sÄ±nÄ±rlayÄ±cÄ± hiperdÃ¼zlem tabanlÄ± modellerin yÃ¼ksek performans gÃ¶stermesinin temel nedenidir.âš™ï¸ MetodolojiVeri YÃ¼kleme ve Ä°nceleme: Veri setinin eksik deÄŸerler ve genel daÄŸÄ±lÄ±mÄ± kontrol edildi.Veri BÃ¶lme: Veri seti, %75 eÄŸitim (X_train, y_train) ve %25 test (X_test, y_test) olarak ayrÄ±ldÄ± (random_state = 42 kullanÄ±larak).Model EÄŸitimi (Linear Kernel): Ä°lk olarak bir Lineer SVM modeli eÄŸitildi.Model EÄŸitimi (RBF Kernel): Ä°kinci olarak bir RBF Kernel SVM modeli eÄŸitildi.DeÄŸerlendirme: EÄŸitimli modellerin performansÄ± classification_report ve confusion_matrix kullanÄ±larak test verisi Ã¼zerinde deÄŸerlendirildi.âœ… SonuÃ§lar ve PerformansLineer SVM modeli, test veri seti Ã¼zerinde neredeyse mÃ¼kemmel bir sÄ±nÄ±flandÄ±rma baÅŸarÄ±sÄ± gÃ¶stermiÅŸtir.MetrikSonuÃ§ (Lineer SVM)DoÄŸruluk (Accuracy)F1-Score (AÄŸÄ±rlÄ±klÄ± Ortalama)Model, yalnÄ±zca bir veya iki test Ã¶rneÄŸinde hata yapmÄ±ÅŸ (yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rmÄ±ÅŸ) olup, bu da veri setindeki sÄ±nÄ±flarÄ±n yÃ¼ksek ayrÄ±labilirliÄŸi gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda beklenen bir durumdur.ğŸ“ Not: RBF Model DeÄŸerlendirmesi HakkÄ±ndaÄ°ncelenen not defterinde, RBF kernel ile bir model eÄŸitilmiÅŸ olmasÄ±na raÄŸmen (rbf.fit(X_train, y_train)), deÄŸerlendirme aÅŸamasÄ±nda yanlÄ±ÅŸlÄ±kla Lineer SVM modelinin (svc.predict(X_test)) Ã§Ä±ktÄ±larÄ± kullanÄ±lmÄ±ÅŸtÄ±r.HatalÄ± Kod SatÄ±rÄ± (DÃ¼zeltilmesi Gerekir):y_pred = svc.predict(X_test) # Burada 'rbf.predict(X_test)' olmalÄ±ydÄ±.
Bu durum, RBF modelinin gerÃ§ek performansÄ±nÄ±n not defterinin mevcut haliyle doÄŸru bir ÅŸekilde gÃ¶sterilmediÄŸi anlamÄ±na gelmektedir. Ancak, Lineer SVM'in yÃ¼ksek performansÄ± nedeniyle RBF kernel'in bu veri setinde Ã¶nemli bir fark yaratmasÄ± beklenmemektedir.ğŸ’» NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±rBu projeyi yerel olarak Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyin:Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:pip install pandas numpy seaborn matplotlib scikit-learn jupyter
SVMClassifier.ipynb ve email_classification_svm.csv dosyalarÄ±nÄ± aynÄ± dizine indirin.Jupyter Notebook'u baÅŸlatÄ±n:jupyter notebook
SVMClassifier.ipynb dosyasÄ±nÄ± aÃ§Ä±n ve hÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±n.ğŸ› ï¸ Gelecek Ä°yileÅŸtirmelerHiperparametre Optimizasyonu: C ve gamma gibi SVM hiperparametrelerini (Ã¶zellikle RBF kernel iÃ§in) GridSearchCV veya RandomizedSearchCV kullanarak optimize etmek.Kod DÃ¼zeltme: RBF modelinin deÄŸerlendirilmesi iÃ§in rbf.predict(X_test) kullanÄ±mÄ±nÄ± dÃ¼zeltmek.Model KaydÄ±: EÄŸitilmiÅŸ en iyi modeli (Linear SVM) gelecekteki kullanÄ±m iÃ§in bir pickle dosyasÄ± olarak kaydetmek.
